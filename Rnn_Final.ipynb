{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fISZmKTap-w"
      },
      "outputs": [],
      "source": [
        "import keras,os\n",
        "from keras.datasets import fashion_mnist, cifar100\n",
        "from keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization\n",
        "from keras.models import Sequential\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras import optimizers\n",
        "from keras.layers.core import Lambda\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from matplotlib import pyplot\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from keras import regularizers\n",
        "from sklearn import datasets # load dataset\n",
        "from sklearn.model_selection import train_test_split # split dataset\n",
        "from sklearn.preprocessing import StandardScaler # standard scaler\n",
        "from sklearn.metrics import accuracy_score # check accuracy\n",
        "from sklearn.linear_model import LinearRegression, Lasso\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from keras.callbacks import EarlyStopping\n",
        "import keras,os\n",
        "from keras.datasets import fashion_mnist, cifar100\n",
        "from keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization\n",
        "from keras.models import Sequential\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from keras import optimizers\n",
        "from keras.layers.core import Lambda\n",
        "from keras import backend as K\n",
        "from keras import regularizers\n",
        "from sklearn import datasets # load dataset\n",
        "from sklearn.model_selection import train_test_split # split dataset\n",
        "from sklearn.preprocessing import StandardScaler # standard scaler\n",
        "from sklearn.metrics import accuracy_score # check accuracy\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrI8ilmnau74",
        "outputId": "0bddde18-866e-4c74-e210-c243b09346ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import the libraries\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_ref = zipfile.ZipFile('/content/drive/MyDrive/crack.zip', 'r') #Opens the zip file in read mode\n",
        "zip_ref.extractall('/tmp') #Extracts the files into the /tmp folder\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "oFmuOhalawww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('/content/drive/MyDrive/crack.zip', 'r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "QEzPsXYMayRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generators\n",
        "train_ds = keras.utils.image_dataset_from_directory(\n",
        "    directory = '/content/crack/train',\n",
        "    labels='inferred',\n",
        "    label_mode = 'int',\n",
        "    batch_size=32,\n",
        "    image_size=(256,256)\n",
        ")\n",
        "\n",
        "validation_ds = keras.utils.image_dataset_from_directory(\n",
        "    directory = '/content/crack/test',\n",
        "    labels='inferred',\n",
        "    label_mode = 'int',\n",
        "    batch_size=32,\n",
        "    image_size=(256,256)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Du3w9kdCa3AT",
        "outputId": "efe6da47-64b2-41f4-c7d9-953edf59c497"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 32000 files belonging to 2 classes.\n",
            "Found 8000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define data generators\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_dir = '/content/crack/train'\n",
        "val_dir = '/content/crack/test'"
      ],
      "metadata": {
        "id": "sVT4gBKja4td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary')\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRrXdNWTa6Tq",
        "outputId": "8b389fc4-74af-4f2d-b132-d1e40950ce69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 32000 images belonging to 2 classes.\n",
            "Found 8000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define the model architecture\n",
        "modelrnn = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "\n",
        "    # Add a Reshape layer to add a third dimension to the output of the Dense layer\n",
        "    tf.keras.layers.Reshape((1, 512)),\n",
        "    # Add a SimpleRNN layer with 64 units\n",
        "    tf.keras.layers.SimpleRNN(64),\n",
        "\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "modelrnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "eoqvp2t2a7sS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, val_acc = modelrnn.evaluate(val_generator, verbose=2)\n",
        "print('validation accuracy:', val_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kS4oKQ89bYET",
        "outputId": "6e27b9ca-5493-4a9e-fe42-3cd9b8386a6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "250/250 - 325s - loss: 0.6924 - accuracy: 0.5000 - 325s/epoch - 1s/step\n",
            "validation accuracy: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = modelrnn.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=20000//1000,\n",
        "    epochs=20,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=20000//1000\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uw0zvIFKbdGm",
        "outputId": "4fad1010-0e44-4edf-8878-2e79ce9132e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "20/20 [==============================] - 129s 6s/step - loss: 1.0122 - accuracy: 0.5141 - val_loss: 0.6931 - val_accuracy: 0.5078\n",
            "Epoch 2/20\n",
            "20/20 [==============================] - 134s 7s/step - loss: 0.6940 - accuracy: 0.4984 - val_loss: 0.6935 - val_accuracy: 0.4547\n",
            "Epoch 3/20\n",
            "20/20 [==============================] - 135s 7s/step - loss: 0.6935 - accuracy: 0.4781 - val_loss: 0.6933 - val_accuracy: 0.4828\n",
            "Epoch 4/20\n",
            "20/20 [==============================] - 116s 6s/step - loss: 0.6944 - accuracy: 0.4906 - val_loss: 0.6941 - val_accuracy: 0.4875\n",
            "Epoch 5/20\n",
            "20/20 [==============================] - 134s 7s/step - loss: 0.6958 - accuracy: 0.4812 - val_loss: 0.6945 - val_accuracy: 0.4969\n",
            "Epoch 6/20\n",
            "20/20 [==============================] - 118s 6s/step - loss: 0.6930 - accuracy: 0.5219 - val_loss: 0.6932 - val_accuracy: 0.5047\n",
            "Epoch 7/20\n",
            "20/20 [==============================] - 134s 7s/step - loss: 0.6936 - accuracy: 0.5047 - val_loss: 0.6933 - val_accuracy: 0.5031\n",
            "Epoch 8/20\n",
            "20/20 [==============================] - 133s 7s/step - loss: 0.6944 - accuracy: 0.4984 - val_loss: 0.6932 - val_accuracy: 0.5094\n",
            "Epoch 9/20\n",
            "20/20 [==============================] - 133s 7s/step - loss: 0.6962 - accuracy: 0.4719 - val_loss: 0.6920 - val_accuracy: 0.5250\n",
            "Epoch 10/20\n",
            "20/20 [==============================] - 141s 7s/step - loss: 0.6932 - accuracy: 0.5109 - val_loss: 0.6916 - val_accuracy: 0.5312\n",
            "Epoch 11/20\n",
            "20/20 [==============================] - 133s 7s/step - loss: 0.6938 - accuracy: 0.4797 - val_loss: 0.6936 - val_accuracy: 0.5063\n",
            "Epoch 12/20\n",
            "20/20 [==============================] - 117s 6s/step - loss: 0.6951 - accuracy: 0.4891 - val_loss: 0.6936 - val_accuracy: 0.4875\n",
            "Epoch 13/20\n",
            "20/20 [==============================] - 133s 7s/step - loss: 0.6926 - accuracy: 0.5328 - val_loss: 0.6984 - val_accuracy: 0.4844\n",
            "Epoch 14/20\n",
            "20/20 [==============================] - 125s 6s/step - loss: 0.6963 - accuracy: 0.5016 - val_loss: 0.6941 - val_accuracy: 0.4938\n",
            "Epoch 15/20\n",
            "20/20 [==============================] - 133s 7s/step - loss: 0.6951 - accuracy: 0.5047 - val_loss: 0.6944 - val_accuracy: 0.4625\n",
            "Epoch 16/20\n",
            "20/20 [==============================] - 133s 7s/step - loss: 0.6925 - accuracy: 0.5250 - val_loss: 0.6925 - val_accuracy: 0.5203\n",
            "Epoch 17/20\n",
            "20/20 [==============================] - 117s 6s/step - loss: 0.6938 - accuracy: 0.5094 - val_loss: 0.7038 - val_accuracy: 0.4719\n",
            "Epoch 18/20\n",
            "20/20 [==============================] - 115s 6s/step - loss: 0.6934 - accuracy: 0.5281 - val_loss: 0.6953 - val_accuracy: 0.4938\n",
            "Epoch 19/20\n",
            "20/20 [==============================] - 141s 7s/step - loss: 0.6965 - accuracy: 0.4656 - val_loss: 0.6925 - val_accuracy: 0.5188\n",
            "Epoch 20/20\n",
            "20/20 [==============================] - 133s 7s/step - loss: 0.6936 - accuracy: 0.5063 - val_loss: 0.6962 - val_accuracy: 0.4859\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " modelrnn.save('/content/crack/rnn_model.h5')\n"
      ],
      "metadata": {
        "id": "-leMgLqNboGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "saved_model = load_model('/content/crack/rnn_model.h5')"
      ],
      "metadata": {
        "id": "Gpvt0w4YbsXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Load and preprocess your input image\n",
        "img_path = \"/content/crack/train/Positive/00177.jpg\"\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "img_array = image.img_to_array(img)\n",
        "img_batch = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "# Make predictions using the loaded model\n",
        "predictions = modelrnn.predict(img_batch)\n",
        "predicted_class = np.argmax(predictions[0])\n",
        "print(predictions)\n",
        "\n",
        "# Print the predicted class label\n",
        "if predicted_class == 0:\n",
        "    print(\"The Image Doesn't Contain Crack !\")\n",
        "else:\n",
        "    print(\"The Image Contains Crack !\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUEHfRJ3b1T8",
        "outputId": "f23d8f52-9788-49ed-af13-1c12d5821d5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 544ms/step\n",
            "[[0.52759624]]\n",
            "The Image Doesn't Contain Crack !\n"
          ]
        }
      ]
    }
  ]
}
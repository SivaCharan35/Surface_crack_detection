{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1Ud_-b98ZNfs"
      },
      "outputs": [],
      "source": [
        "import keras,os\n",
        "from keras.datasets import fashion_mnist, cifar100\n",
        "from keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization\n",
        "from keras.models import Sequential\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from keras import optimizers \n",
        "from keras.layers.core import Lambda \n",
        "from keras import backend as K \n",
        "from tensorflow.keras.preprocessing import image\n",
        "from matplotlib import pyplot\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from keras import regularizers\n",
        "from sklearn import datasets # load dataset\n",
        "from sklearn.model_selection import train_test_split # split dataset\n",
        "from sklearn.preprocessing import StandardScaler # standard scaler\n",
        "from sklearn.metrics import accuracy_score # check accuracy\n",
        "from sklearn.linear_model import LinearRegression, Lasso\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.datasets import fashion_mnist, cifar100\n",
        "from keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization\n",
        "from keras.models import Sequential\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from keras import optimizers\n",
        "from keras.layers.core import Lambda\n",
        "from keras import backend as K\n",
        "from keras import regularizers\n",
        "from sklearn import datasets # load dataset\n",
        "from sklearn.model_selection import train_test_split # split dataset\n",
        "from sklearn.preprocessing import StandardScaler # standard scaler\n",
        "from sklearn.metrics import accuracy_score # check accuracy\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "0KxImVrjZQzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import the libraries\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_ref = zipfile.ZipFile('/content/drive/MyDrive/crack.zip', 'r') #Opens the zip file in read mode\n",
        "zip_ref.extractall('/tmp') #Extracts the files into the /tmp folder\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "iRvIJXgHZRCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('/content/drive/MyDrive/crack.zip', 'r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "TN65aReVZRV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generators\n",
        "train_ds = keras.utils.image_dataset_from_directory(\n",
        "    directory = '/content/crack/train',\n",
        "    labels='inferred',\n",
        "    label_mode = 'int',\n",
        "    batch_size=32,\n",
        "    image_size=(256,256)\n",
        ")\n",
        "\n",
        "validation_ds = keras.utils.image_dataset_from_directory(\n",
        "    directory = '/content/crack/test',\n",
        "    labels='inferred',\n",
        "    label_mode = 'int',\n",
        "    batch_size=32,\n",
        "    image_size=(256,256)\n",
        ")"
      ],
      "metadata": {
        "id": "JEUDkYkiZRrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define data generators\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_dir = '/content/crack/train'\n",
        "val_dir = '/content/crack/test'"
      ],
      "metadata": {
        "id": "OMQSl-l8ZeZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary')\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='binary')"
      ],
      "metadata": {
        "id": "ikM9Sv9cZgGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VGG16"
      ],
      "metadata": {
        "id": "3MmS4xFAZl06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "\n",
        "# Load the pre-trained VGG16 model without the top (classification) layer\n",
        "vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the layers of the pre-trained model\n",
        "for layer in vgg16.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Create a new model and add the VGG16 base model\n",
        "model1 = Sequential()\n",
        "model1.add(vgg16)\n",
        "\n",
        "# Add custom classification layers on top of the VGG16 base\n",
        "model1.add(Flatten())\n",
        "model1.add(Dense(512, activation='relu'))\n",
        "model1.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "K3aSokjSZnT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the model summary\n",
        "model1.summary()"
      ],
      "metadata": {
        "id": "w41jIyCQZpz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils.vis_utils import plot_model"
      ],
      "metadata": {
        "id": "kdJAovNLZrAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(model1, to_file='model_plot.png', show_shapes=True, show_layer_names=True)  "
      ],
      "metadata": {
        "id": "dGcKH7nQZsXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "7OkpZTBBZ0lu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, val_acc = model1.evaluate(val_generator, verbose=2)\n",
        "print('validation accuracy:', val_acc)"
      ],
      "metadata": {
        "id": "uKcs0Ed9ZvwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model1.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=20000//1000,\n",
        "    epochs=20,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=20000//1000\n",
        ")"
      ],
      "metadata": {
        "id": "6nXJCichZxKY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}